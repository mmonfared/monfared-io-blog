[{"categories":null,"content":"What is Appium? Appium is an open-source project and ecosystem designed to facilitate UI automation for a wide range of app platforms, including:\nMobile: iOS, Android, Tizen Browser: Chrome, Firefox, Safari Desktop: macOS, Windows TV: Roku, tvOS, Android TV, Samsung, and more. In other words, Appium does the same as selenium but for mobile applications! With the release of Appium 2.0, it aims to achieve the following primary goals:\nMake platform-specific automation capabilities available under a cross-platform, standard API (Compatible with W3C WebDriver protocol). Allow easy access to this API from any programming language. Provide tools for convenient community development of Appium extensions. Appium Architecture\nAppium leverages the WebDriver specification as its API (Including groundbreaking Actions API for its Gestures actions). This choice was influenced by Selenium, a long-standing pioneer in UI automation for web browsers. Selenium\u0026rsquo;s stable API for browser automation served as a solid foundation, and Appium extended it to support mobile apps (iOS and Android). By adopting the WebDriver spec, Appium ensures a unified approach to automation across platforms.\nWhile user interactions on websites and native mobile apps differ, the commonalities in software UIs allow the WebDriver spec to map effectively to any platform. Appium\u0026rsquo;s goal is to provide a consistent experience for developers and testers, regardless of the underlying technology. In this series of articles, I will explain in detail how to use Appium to perform mobile gestures like zoom, scroll, swipe, drag and drop, and more, using the latest techniques and APIs.\nW3C Actions API W3C Mobile Gestures Actions UiScrollable Class (Deprecated) Appium Gestures Plugin TouchAction | MultiAction (Deprecated, but it is worth mentioning since a lot of projects still use it) You will not find all of them in one place except here! So let\u0026rsquo;s get started 🚀\nSome mobile gestures\nI\u0026rsquo;ll show how to do the gestures in \u0026ldquo;Android \u0026ldquo;and in later articles, I will write about them in iOS. Git Repository: All the codes written in this series of articles are pushed to the following repository, so feel free to use it as a reference: automationcamp-appium Github Repo Install and setup project If you haven\u0026rsquo;t installed Appium yet, please follow this article. I explained step by step how to setup an appium project. For the demo, we will use appium official ApiDemos application which you can find in the above repository APK folder or directly from appium repo. Now:\nCreate a Python file like appium_gestures.py (test file) Import all the following classes/libraries. (Look at the comments) # Main appium driver from appium import webdriver # It is used to locate elements from appium.webdriver.common.appiumby import AppiumBy # It is used to create a UiAutomator2 driver instance from appium.options.android import UiAutomator2Options # W3C compatible gestures helper librart created to update driver\u0026#39;s default gestures from appium.webdriver.extensions.action_helpers import ActionHelpers # W3C compatible libraries to create any gestures rather than driver\u0026#39;s default gestures from selenium.webdriver.common.actions.action_builder import ActionBuilder from selenium.webdriver.common.action_chains import ActionChains from selenium.webdriver.common.actions.mouse_button import MouseButton from selenium.webdriver.common.actions.pointer_input import PointerInput from selenium.webdriver.common.actions import interaction # Old touch action libraries (Deprecated and will remove soon) from appium.webdriver.common.touch_action import TouchAction from appium.webdriver.common.multi_action import MultiAction # It is used to demo purposes. from time import sleep Set the appium server URL globally in the file: appium_server = \u0026#34;http://127.0.0.1:4723\u0026#34; Create a file named desired_caps.py in the project root and add the following dictionaries in it: apidemos = { \u0026#34;platformName\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;appium:options\u0026#34;: { \u0026#34;appPackage\u0026#34;: \u0026#34;io.appium.android.apis\u0026#34;, \u0026#34;appActivity\u0026#34;: \u0026#34;.ApiDemos\u0026#34;, \u0026#34;:automationName\u0026#34;: \u0026#34;UiAutomator2\u0026#34; } } contacts = { \u0026#34;appium:appPackage\u0026#34;: \u0026#34;com.android.contacts\u0026#34;, \u0026#34;appium:appActivity\u0026#34;: \u0026#34;.activities.PeopleActivity\u0026#34;, \u0026#34;platformName\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;appium:automationName\u0026#34;: \u0026#34;UiAutomator2\u0026#34; } maps = { \u0026#34;appium:appPackage\u0026#34;: \u0026#34;com.google.android.apps.maps\u0026#34;, \u0026#34;appium:appActivity\u0026#34;: \u0026#34;com.google.android.maps.MapsActivity\u0026#34;, \u0026#34;platformName\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;appium:automationName\u0026#34;: \u0026#34;UiAutomator2\u0026#34; } chrome = { \u0026#34;platformName\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;browserName\u0026#34;: \u0026#34;Chrome\u0026#34;, \u0026#34;appium:options\u0026#34;: { \u0026#34;automationName\u0026#34;: \u0026#34;UiAutomator2\u0026#34;, # \u0026#34;chromedriverExecutable\u0026#34;: \u0026#34;C:/chromedriver.exe\u0026#34; } } then add the following import statement to the test file.\nimport desired_caps Get window and element rectangular / size Doing precise gestures on the display needs interaction with coordination and calculations related to the positions of the elements or display size. Before diving into gestures we should be aware of them.\nElement Rectangular\nDisplay Rectangular: In the figure above, the black box represents the Display, which is currently in landscape view. We measure the Size of the Display in pixels (Height/Width), for example, 800px*1440px. Note that this is not the same as the device dimensions, which are measured in inches. The screen size of applications and the display resolution are determined based on display density. Additionally, the app\u0026rsquo;s window may not be entirely maximized, so it could be located anywhere on the screen. The (x,y) coordinates of the top-left corner of this window are referred to as the Location or Coordination.\nThe following command returns the rectangle of a window, including its X and Y coordinates, as well as its height and width.\nwindow_rect = driver.get_window_rect() # {\u0026#39;height\u0026#39;: \u0026#39;800\u0026#39;, \u0026#39;width: \u0026#39;1440\u0026#39;, \u0026#39;x\u0026#39;: 100, \u0026#39;y\u0026#39;: 200} Also, if we just want the Window Size, we can use the following command:\nwindow_rect = driver.get_window_size() # {\u0026#39;height\u0026#39;: \u0026#39;800\u0026#39;, \u0026#39;width: \u0026#39;1440\u0026#39;} Element Rectangular: Each element within a window has its own rectangular properties, including its Size and Location on the page. The size of an element is defined in terms of its Height and Width in pixels, while its location is determined by measuring the distance from the top-left corner of the screen. To obtain these values, we can use the following method:\n# First we find the element and store its object in a value el = driver.find_element(by=AppiumBy.ACCESSIBILITY_ID, value=\u0026#39;Button\u0026#39;) # Then the \u0026#34;rect\u0026#34; and \u0026#34;location\u0026#34; are what we need: print(el.rect) # {\u0026#39;height\u0026#39;: \u0026#39;100\u0026#39;, \u0026#39;width: \u0026#39;150\u0026#39;, \u0026#39;x\u0026#39;: 840, \u0026#39;y\u0026#39;: 680} print(el.location) # {\u0026#39;x\u0026#39;: 840, \u0026#39;y\u0026#39;: 680} Calculate the center of an element: If we want to execute a gesture on an element object, we can pass the element object to the relevant command. The driver will automatically perform the gesture at the center of the element. However, if we want to pass the coordinates of the element instead and perform the action on the center, we need to calculate its center point first. This is often necessary as the location attribute returns the coordinates of the element\u0026rsquo;s top-left corner, and we need to determine the center point ourselves. The center point is shown in purple as (x,y) in the above figure.\nThe following code can be used to do it:\nel = driver.find_element(by=AppiumBy.ACCESSIBILITY_ID, value=\u0026#39;Button\u0026#39;) center_x = el.rect[\u0026#39;x\u0026#39;] + el.rect[\u0026#39;width\u0026#39;]/2 center_y = el.rect[\u0026#39;y\u0026#39;] + el.rect[\u0026#39;height\u0026#39;]/2 Ok, let\u0026rsquo;s do the very first gesture which is tapping!\nW3C Actions API Let\u0026rsquo;s take a quick look at the libraries and history of gesture commands. Selenium has its own libraries for mouse actions called \u0026ldquo;TouchActions\u0026rdquo; and \u0026ldquo;ActionChains\u0026rdquo;. While it can handle almost all mouse actions on the web, it may not be completely useful for mobile gesture actions. Therefore, the Appium team had to develop libraries called \u0026ldquo;TouchAction\u0026rdquo; and \u0026ldquo;MultiAction\u0026rdquo;. Let\u0026rsquo;s take a closer look at the comments written by the Appium team at the top of the TouchAction class.\ntouch-action.py comments\nIt worked for many years, but in 2018, WebDriver became a W3C standard and introduced the Actions API in section 15 of its specifications. Selenium and its sub-projects, including Appium, must follow these specifications.\nW3C Webdriver Protocol -The Actions API\nBy introducing the concepts of Multiple Pointer Inputs and Ticks, it became possible to create almost any gesture by simulating parallel sequences. For instance, you can make a zoom gesture by moving two fingers in opposite directions. You can even draw on the screen! The Appium team explained this concept very well in an article , which you can read to get a better understanding.\nSource: https://appiumpro.com/editions/29-automating-complex-gestures-with-the-w3c-actions-api\nW3C Mobile Gestures Commands We know that in Selenium/Appium, JavaScript commands can be executed using driver.execute_script() , so it opens the door to leveraging the power of JavaScript to perform complex tasks like gestures in the page or app. Thanks to the Appium team, we have a range of commands implemented to perform gestures and they work well in most cases.\nmobile: dragGesture mobile: flingGesture mobile: doubleClickGesture mobile: clickGesture mobile: longClickGesture mobile: pinchCloseGesture mobile: pinchOpenGesture mobile: swipeGesture mobile: scrollGesture A notable advantage of using these commands is their multi-platform compatibility. You can use the same commands with slight change in syntax for both iOS and Android, eliminating the need for driver-specific commands. (UiAutmator2 driver in android and XCUITest in iOS ).\nSo Selenium has implemented W3C actions and updated the ActionChains class, which allows you to use the same class for both Appium and Selenium. You can create your own gestures using this class. Also, there are some official helper classes available for popular gestures using W3C Actions such as driver.swipe() and driver.drag_and_drop() or Mobile Gestures Commands in the latest version of the Appium Python client. We will implement each gesture using all available options in the following articles! Thank you for taking the time to read. If you enjoyed the post, please leave your comments, questions, and reactions. Your feedback is greatly appreciated!\nIn the next article, we will cover Tap, Multi-Finger Tap, and Double-Tap gestures.\nFollow me on LinkedIn: https://www.linkedin.com/in/mohammad-monfared/ Happy testing ✌️\n","permalink":"http://localhost:1313/posts/1-appium-gestures-part1/","tags":null,"title":"Gestures in Appium - Part 1 - History | Element/Display Rectangular | W3C ActionsAPI | Setup"}]